# Cargar librerias
library(MASS)
library(carData)
library(caret)
library(car)
library(nortest)
library(lmtest)
library(corrplot)
library(leaps)
library(glmnet)
library(pls)
library(e1071)
library(ROCR)



# Definir función predict.regsubsets
predict.regsubsets <- function(object, newdata, id,...){
  form <-as.formula(object$call[[2]])
  mat <- model.matrix(form,newdata)
  coefi <- coef(object,id=id)
  xvars <- names(coefi)
  mat[,xvars]%*%coefi
}

# ESTUDIO DESCRIPTIVO DATASET 

# Cargar datos
datos <- read.csv(file="C:\\Users\\mario\\Downloads\\IndianWaterQuality.csv")

# Mostrar resumen de datos
summary(datos)
head(datos)

# Eliminar filas con valores NA
datos = na.omit(datos)

# Mostrar resumen actualizado de datos
summary(datos)
head(datos)

# Crear gráficos para cada variable
par(mfrow = c(3, 3))  # 3 filas y 3 columnas
for (col in names(datos)) {
  if (col != "Habitation.Name" && col != "Year") {
    hist(datos[[col]], main = col, xlab = col, col = "turquoise", border = "black")
  }
}

dim(datos)

#Dejamos preparado este conjunto para más adelante la regresión logística
datos_logistica <- subset(datos, select = -c(Habitation.Name, Year))

# Eliminar columnas "Habitation.Name" , "Year" (strings) y "Potability" (booleans)
datos <- subset(datos, select = -c(Habitation.Name, Year, Potability))
summary(datos)
head(datos)


# REGRESION LINEAL MULTIPLE

# Ajustar modelo de regresión lineal
modelo <- lm(ph ~ ., data=datos)
summary(modelo) # Mostrar resumen del modelo ajustado

# Ver simetría
skewness(datos$ph)
skewness(datos$Hardness)
skewness(datos$Solids)
skewness(datos$Chloramines)
skewness(datos$Sulfate)
skewness(datos$Conductivity)
skewness(datos$Organic_carbon)
skewness(datos$Trihalomethanes)
skewness(datos$Turbidity)
# Son todas simétricas dado que el skewness está entre 2 y -2.


# Boxplot de la variable dependiente "ph"
boxplot(datos$ph, main="Boxplot de ph", ylab="ph")

# Boxplots de las variables independientes
for (col in colnames(datos)) {
  if (col != "ph") {
    boxplot(datos[, col], main=paste("Boxplot de", col), ylab=col)
  }
}

# Elimimar outliers influyentes
boxplot.stats(datos$ph, coef = 3)

datos <- datos[!(datos$ph %in% boxplot.stats(datos$ph)$out), ]

# Ahora, datos contiene el conjunto de datos sin los outliers en la variable "ph"

boxplot.stats(datos$Hardness, coef = 3)
boxplot.stats(datos$Solids, coef = 3)
boxplot.stats(datos$Chloramines, coef = 3)
boxplot.stats(datos$Sulfate, coef = 3)

datos <- datos[!(datos$Sulfate %in% boxplot.stats(datos$Sulfate)$out), ]
# Ahora, datos contiene el conjunto de datos sin los outliers en la variable "Sulfate"

boxplot.stats(datos$Conductivity, coef = 3)
boxplot.stats(datos$Organic_carbon, coef = 3)
boxplot.stats(datos$Trihalomethanes, coef = 3)
boxplot.stats(datos$Turbidity, coef = 3)

# Boxplot de la variable dependiente "ph" después de eliminar outliers
boxplot(datos$ph, main="Boxplot de ph (sin outliers)", ylab="ph", range = 3)

# Boxplots de las variables independientes después de eliminar outliers
for (col in colnames(datos)) {
  if (col != "ph") {
    boxplot(datos[, col], main=paste("Boxplot de", col, "(sin outliers)"), ylab=col, range = 3)
  }
}

dim(datos)
summary(datos)

# Calculamos correlacion
cor(x=datos, method="spearman")
# No es necesario eliminar nada dado que no hay una correlacion mayor que 0,7 ni menor que -0,7

# Mostrar correlaciones actualizadas
corrplot(corr = cor(x = datos, method = "spearman"), method = "number",
         tl.cex = 1,number.cex = 1, cl.pos = "n",
         main="Coeficiente de Spearman")

# Ajustar modelo de regresión lineal
modelo <- lm(ph ~ ., data=datos)
summary(modelo) # Mostrar resumen del modelo ajustado

# Crear gráficos para cada variable sin outliers
par(mfrow = c(3, 3))  # 3 filas y 3 columnas
for (col in names(datos)) {
  hist(datos[[col]], main = col, xlab = col, col = "turquoise", border = "black")
}
# Restaurar la configuración original de par() para evitar efectos secundarios
par(mfrow = c(1, 1))


# Separamos en Train y Test
set.seed(1)
train = sample(c(TRUE,FALSE),size = nrow(datos), replace = TRUE, prob = c(0.8, 0.2))
datos.train = datos[train,]
datos.test = datos[!train,]

modelo <- lm(ph ~ .,data=datos.train)
summary(modelo) # Mostramos el modelo ajustado

## Gráfico de residuos contra valores ajustados
plot(modelo, which = c(1, 2))
par(mfrow = c(1, 1))

# Gráfico QQ
qqPlot(modelo, main = "Gráfico QQ")

## VALIDACIÓN CRUZADA k-folds
k <- 5 # Número de grupos igual a n
set.seed(5)
folds <- sample(x=1:k, size =nrow(datos.train), replace = TRUE)
cv.errors <- matrix(NA, k, 8, dimnames = list(NULL,paste(1:8)))
for (j in 1:k){
  regfit.best <- regsubsets(ph~., data=datos.train[folds !=j,])
  for (i in 1:8){
    pred <- predict.regsubsets(regfit.best, newdata=datos.train[folds==j,], id=i)
    cv.errors[j,i] <- mean((datos.train$ph[folds == j]-pred)^2)
  }
}
cv.errors

mean.cv.errors <- apply(cv.errors, 2, mean)
mean.cv.errors
coef(regfit.best, which.min(mean.cv.errors))
# Comprobación
model.cv <- lm(ph ~ Hardness + Solids, data=datos.train)
summary(model.cv)
plot(lm(ph ~ Hardness + Solids, data=datos.train))
plot(lm(ph ~ Hardness + Solids, data=datos.train), which=c(1,2))
residualPlot(model.cv)
influenceIndexPlot(model.cv)
durbinWatsonTest(model.cv)

# Por los valores obtenidos podemos concluir que no existe multicolinealidad entre las variables
(vif=vif(model.cv))
(tol=1/vif)

# Por ultimo, evaluamos los supuestos de normalidad, independencia y homocedasticidad.
summary(model.cv)
confint(model.cv) # Mostramos los intervalos de confianza de los coeficientes
residuos=model.cv$residuals
plot(residuos)
hist(residuos)
boxplot(residuos)
boxplot.stats(residuos, coef = 3)


#Estudiamos la normalidad
lillie.test(residuos)

#Estudiamos la homocedasticidad
bptest(model.cv)

#Estudiamos la independencia
dwtest(model.cv)

# Observamos que los residuos verifican los tres supuestos anteriores.

#Calculamos el ECM y su raíz
pred = predict(model.cv,newdata=datos.test)
ECM = mean((pred-datos.test$ph)^2)
ECM
RMSE=(sqrt(ECM))
RMSE


# MÉTODO RIDGE

x<-model.matrix(ph~.,datos.train)[,-1]
y<-datos.train$ph
grid<-10^seq(10,-2,length=100)
ridge.mod<-glmnet(x,y,alpha=0,lambda=grid)

x.train<-model.matrix(ph~.,datos.train)[,-1]
y.train<-datos.train$ph
x.test<-model.matrix(ph~.,datos.test)[,-1]
y.test<-datos.test$ph


set.seed(1)
cv.out<-cv.glmnet(x.train,y.train,alpha=0)
plot(cv.out)
(bestlam<-cv.out$lambda.min)

ridge.pred<-predict(ridge.mod,s=bestlam,newx=x.test)
ECM = mean((ridge.pred-y.test)^2)
ECM
RMSE=(sqrt(ECM))
RMSE

out<-glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)

# Gráfico de coeficientes Ridge
plot(ridge.mod, xvar="lambda", label=TRUE)


# MÉTODO LASSO

lasso.mod<-glmnet(x.train,y.train,alpha=1,lambda=grid)
plot(lasso.mod)

set.seed(1)
cv.out<-cv.glmnet(x.train,y.train,alpha=1)
plot(cv.out)
bestlam<-cv.out$lambda.min
lasso.pred<-predict(lasso.mod,s=bestlam,newx=x.test)
mean((lasso.pred-y.test)^2)
sqrt(mean((lasso.pred-y.test)^2))

out<-glmnet(x,y,alpha=1,lambda=grid)
lasso.coef<-predict(out,type="coefficients",s=bestlam)
lasso.coef
lasso.coef[lasso.coef!=0]

# Gráfico de coeficientes Lasso
plot(lasso.mod, xvar="lambda", label=TRUE)


# MÉTODO ELASTIC NET

# En caso de querer seleccionar el valor de α que minimice el ECM del modelo, lo podemos
# obtener comenzando con el siguiente bucle:

models <- list()
for (i in 0:20) {
  name <- paste0("alpha", i/20)
  models[[name]] <-
    cv.glmnet(x.train,y.train, type.measure="mse", alpha=i/20)
}

# Con este bucle, hemos ejecutado la funcion cv.glmnet() 21 veces, cada una de ellas con
# un valor de α diferente, tomando incrementos de tamaño 0.05. Queremos explorar estos
# modelos mas de cerca para ver cual produce el mejor ajuste del modelo,

results <- data.frame()
for (i in 0:20) {
  name <- paste0("alpha", i/20)
  ## Utilizamos cada modelo para predecir ’y’ dado el conjunto de datos de prueba
  predicted <- predict(models[[name]],
                       s=models[[name]]$lambda.min, newx=x.test)
  ## Calculamos el ECM
  mse <- mean((predicted-y.test)^2)
  ## Almacenamos los resultados
  temp <- data.frame(alpha=i/20, lambda=models[[name]]$lambda.min, mse=mse, name=name)
  results <- rbind(results, temp)
}
print(results)

plot(results$alpha, results$mse)
pos.min=which.min(results$mse)
(minimo=results[pos.min,])

# Como podemos ver, el valor de α que produce el mejor ajuste (minimiza el ECM) es 0.85
# y el modelo resultante contiene los siguientes predictores:
out<-glmnet(x,y,alpha=minimo$alpha,lambda=minimo$lambda)
elasnet.coef<-predict(out,type="coefficients",s=bestlam)
elasnet.coef
elasnet.coef[elasnet.coef!=0]



# MÉTODOS DE REDUCCIÓN DE DIMENSIONES

# PCR

set.seed(1)
pcr.fit<-pcr(ph~.,data=datos.train,scale=TRUE,validation="CV")
validationplot(pcr.fit,val.type="MSEP")
MSEP(pcr.fit)

# Ahora encontramos que el error de validacion cruzada mas bajo ocurre cuando se usan M = 4 componentes. Calculamos el ECM en el conjunto de prueba de la siguiente manera.
pcr.pred<-predict(pcr.fit,x.test,ncomp=4)
mean((pcr.pred-y.test)^2)
sqrt(mean((pcr.pred-y.test)^2))


# PLS (el enfoque PLS intenta encontrar direcciones que ayuden a explicar tanto la respuesta como los predictores)

set.seed(1)
pls.fit<-plsr(ph~., data = datos.train, scale = TRUE, validation = "CV")
summary(pls.fit)
validationplot(pls.fit,val.type="MSEP")

# Realizamos ahora el PLS usando el conjunto de datos train, usando M = 1, el numero de
# componentes identificados por validacion cruzada.
pls.fit<-plsr(ph~.,data=datos.train,scale=TRUE,ncomp=1)
summary(pls.fit)

# Ahora evaluamos el correspondiente ECM del conjunto de prueba.
pls.pred<-predict(pls.fit,x.test,ncomp=1)
mean((pls.pred-y.test)^2)
sqrt(mean((pls.pred-y.test)^2))


# REGRESIÓN LOGÍSTICA

names(datos_logistica) #obtenemos los nombres de las caracterısticas
dim(datos_logistica) #obtenemos la dimension de la matriz
summary(datos_logistica)

par(mfrow = c(3, 3))

# Boxplot de la variable dependiente "ph"
boxplot(datos_logistica$ph, main="Boxplot de ph", ylab="ph")

# Boxplots de las variables independientes
for (col in colnames(datos_logistica)) {
  if (col != "ph") {
    boxplot(datos_logistica[, col], main=paste("Boxplot de", col), ylab=col)
  }
}

# Elimimar outliers influyentes
boxplot.stats(datos_logistica$ph, coef = 3)

datos_logistica <- datos_logistica[!(datos_logistica$ph %in% boxplot.stats(datos_logistica$ph)$out), ]

# Ahora, datos contiene el conjunto de datos sin los outliers en la variable "ph"

boxplot.stats(datos_logistica$Hardness, coef = 3)
boxplot.stats(datos_logistica$Solids, coef = 3)
boxplot.stats(datos_logistica$Chloramines, coef = 3)
boxplot.stats(datos_logistica$Sulfate, coef = 3)

datos_logistica <- datos_logistica[!(datos_logistica$Sulfate %in% boxplot.stats(datos_logistica$Sulfate)$out), ]
# Ahora, datos contiene el conjunto de datos sin los outliers en la variable "Sulfate"

boxplot.stats(datos_logistica$Conductivity, coef = 3)
boxplot.stats(datos_logistica$Organic_carbon, coef = 3)
boxplot.stats(datos_logistica$Trihalomethanes, coef = 3)
boxplot.stats(datos_logistica$Turbidity, coef = 3)

# Boxplot de la variable dependiente "ph" después de eliminar outliers
boxplot(datos_logistica$ph, main="Boxplot de ph (sin outliers)", ylab="ph", range = 3)

# Boxplots de las variables independientes después de eliminar outliers
for (col in colnames(datos_logistica)) {
  if (col != "ph") {
    boxplot(datos_logistica[, col], main=paste("Boxplot de", col, "(sin outliers)"), ylab=col, range = 3)
  }
}

dim(datos_logistica)
par(mfrow = c(1, 1))

umbral_ph <- 7

# Crear la variable dicotómica (más de 7 de ph es 1 lo que significa que el ph es alcalino, y al contrario que es ácido)
datos_logistica$ph_categorico <- ifelse(datos_logistica$ph > umbral_ph, 1, 0)

modelo_logistico <- glm(ph_categorico ~ Hardness + Solids + Chloramines + Sulfate + Conductivity + Organic_carbon + Trihalomethanes + Turbidity, 
                        data = datos_logistica, 
                        family = binomial)

# Mostrar resumen del modelo
summary(modelo_logistico)


# Asegúrate de que ph_categorico sea un factor con dos niveles
datos_logistica$ph_categorico <- as.factor(datos_logistica$ph_categorico)


# Separa los datos en conjuntos de entrenamiento y prueba
set.seed(1)
train = sample(c(TRUE,FALSE),size = nrow(datos_logistica), replace = TRUE, prob = c(0.7, 0.3))
datos_logistica.train <- datos_logistica[train, ]
datos_logistica.test <- datos_logistica[-train, ]

modelo_logistica <- glm(ph_categorico ~ Hardness + Solids + Chloramines + Sulfate + Conductivity + Organic_carbon + Trihalomethanes + Turbidity, data=datos_logistica.train, family=binomial)
summary(modelo_logistica) # Mostramos el modelo ajustado

# Ajuste del modelo de regresión logística con validación cruzada LOOCV
model <- train(ph_categorico ~ Hardness,
               data = datos_logistica.train,
               method = "glm",
               family = binomial,
               trControl = trainControl(method = "LOOCV"))

levels(datos_logistica$ph_categorico)

# Mostrar un resumen del modelo
model

# Realizar predicciones en los datos de prueba
glm.pred <- predict(model, datos_logistica.test)


# Calcular la matriz de confusión
confusionMatrix(glm.pred, datos_logistica.test$ph_categorico)
# Definir las etiquetas de clase
classes <- c("Ácido", "Alcalino")
# Calcular la matriz de confusión
conf_mat <- confusionMatrix(factor(glm.pred), factor(datos_logistica.test$ph_categorico), positive = "1", dnn = c("Actual", "Predicted"), mode = "everything")

# Cambiar las etiquetas de clase en la matriz de confusión
rownames(conf_mat$table) <- classes
colnames(conf_mat$table) <- classes

# Mostrar la matriz de confusión
conf_mat$table


#                Actual
#                0 (Ácido)   1 (Alcalino)

# Predicted  0       TN            FP
#            1       FN            TP

#TN (True Negative): Observaciones que son correctamente clasificadas como ácidas (clase 0).
#FP (False Positive): Observaciones que son incorrectamente clasificadas como alcalinas (clase 1), pero son ácidas (clase 0).
#FN (False Negative): Observaciones que son incorrectamente clasificadas como ácidas (clase 0), pero son alcalinas (clase 1).
#TP (True Positive): Observaciones que son correctamente clasificadas como alcalinas (clase 1).

VP=conf_mat$table[1,1]
VN=conf_mat$table[2,2]
FP=conf_mat$table[1,2]
FN=conf_mat$table[2,1]
(accuracy=(VP+VN)/(VP+FN+VN+FP)) # En conclusión, tengo un 56'41% de acierto.
(error=(FN+FP)/(VP+FN+VN+FP))
(sensibilidad=VP/(VP+FN))
(especificidad=VN/(VN+FP))
(vpp=VP/(VP+FP))
(vpn=VN/(VN+FN))
(F1=2*(vpp*sensibilidad)/(vpp+sensibilidad))


# Área bajo la curva (AUC) para la curva ROC
pred <- prediction(as.numeric(glm.pred), as.numeric(datos_logistica.test$ph_categorico))
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE, type = "l")
abline(a = 0, b = 1)

# Calcular el AUC
AUC <- performance(pred, measure = "auc")
AUCaltura <- AUC@y.values
cat("AUC:", AUCaltura[[1]])
