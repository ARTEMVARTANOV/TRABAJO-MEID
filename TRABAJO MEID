# Cargar librerias
library(MASS)
library(carData)
library(caret)
library(car)
library(nortest)
library(lmtest)
library(corrplot)
library(leaps)
library(glmnet)
library(pls)
library(e1071)
library(ROCR)
library(olsrr)
library(AICcmodavg)
library(flexmix)
library(psych)




# Definir función predict.regsubsets
predict.regsubsets <- function(object, newdata, id,...){
  form <-as.formula(object$call[[2]])
  mat <- model.matrix(form,newdata)
  coefi <- coef(object,id=id)
  xvars <- names(coefi)
  mat[,xvars]%*%coefi
}

# ESTUDIO DESCRIPTIVO DATASET 

# Cargar datos
datos <- read.csv(file="C:\\Users\\mario\\Downloads\\IndianWaterQuality.csv")

# Mostrar resumen de datos
summary(datos)
head(datos)

# Eliminar filas con valores NA
datos = na.omit(datos)

# Mostrar resumen actualizado de datos
summary(datos)
head(datos)

# Crear gráficos para cada variable
par(mfrow = c(3, 3))  # 3 filas y 3 columnas
for (col in names(datos)) {
  if (col != "Habitation.Name" && col != "Year") {
    hist(datos[[col]], main = col, xlab = col, col = "turquoise", border = "black")
  }
}

dim(datos)

#Dejamos preparado este conjunto para más adelante la regresión logística
datos_logistica <- subset(datos, select = -c(Habitation.Name, Year))

# Eliminar columnas "Habitation.Name" , "Year" (strings) y "Potability" (booleans)
datos <- subset(datos, select = -c(Habitation.Name, Year, Potability))
summary(datos)
describe(datos)
head(datos)


# REGRESION LINEAL MULTIPLE

# Ajustar modelo de regresión lineal
modelo <- lm(ph ~ ., data=datos)
summary(modelo) # Mostrar resumen del modelo ajustado

# Ver simetría
skewness(datos$ph)
skewness(datos$Hardness)
skewness(datos$Solids)
skewness(datos$Chloramines)
skewness(datos$Sulfate)
skewness(datos$Conductivity)
skewness(datos$Organic_carbon)
skewness(datos$Trihalomethanes)
skewness(datos$Turbidity)
# Son todas simétricas dado que el skewness está entre 2 y -2.


# Boxplot de la variable dependiente "ph"
boxplot(datos$ph, main="Boxplot de ph", ylab="ph", range = 3)

# Boxplots de las variables independientes
for (col in colnames(datos)) {
  if (col != "ph") {
    boxplot(datos[, col], main=paste("Boxplot de", col), ylab=col, range = 3)
  }
}

boxplot(datos$ph, main="Boxplot de ph", ylab="ph")

# Boxplots de las variables independientes
for (col in colnames(datos)) {
  if (col != "ph") {
    boxplot(datos[, col], main=paste("Boxplot de", col), ylab=col)
  }
}

# Eliminar outliers influyentes y algunos no influyentes (los más extremos)
# PH
boxplot.stats(datos$ph, coef = 3)
datos$ph <- as.numeric(trimws(datos$ph))
datos <- datos[datos$ph != 14, ]
boxplot.stats(datos$ph, coef = 2)
datos <- datos[round(datos$ph, 7) != round(13.3498886, 7), ]
datos <- datos[round(datos$ph, 7) != round(0.2274991, 7), ]
datos <- datos[round(datos$ph, 7) != round(0.9899122, 7), ]
# Hardness
boxplot.stats(datos$Hardness, coef = 3)
boxplot.stats(datos$Hardness, coef = 2)
datos <- datos[round(datos$Hardness, 5) != round(317.33812, 5), ]
datos <- datos[round(datos$Hardness, 5) != round(306.62748, 5), ]
datos <- datos[round(datos$Hardness, 5) != round(300.29248, 5), ]
datos <- datos[round(datos$Hardness, 5) != round(73.49223, 5), ]
datos <- datos[round(datos$Hardness, 5) != round(77.45959, 5), ]
datos <- datos[round(datos$Hardness, 5) != round(81.71090, 5), ]
# Solids
boxplot.stats(datos$Solids, coef = 3)
boxplot.stats(datos$Solids, coef = 2)
datos <- datos[round(datos$Solids, 2) != round(56488.67, 2), ]
datos <- datos[round(datos$Solids, 2) != round(56351.40, 2), ]
# Chloramines
boxplot.stats(datos$Chloramines, coef = 3)
boxplot.stats(datos$Chloramines, coef = 2)
datos <- datos[round(datos$Chloramines, 6) != round(1.390871, 6), ]
datos <- datos[round(datos$Chloramines, 6) != round(1.920271, 6), ]
datos <- datos[round(datos$Chloramines, 6) != round(13.127000, 6), ]
datos <- datos[round(datos$Chloramines, 6) != round(13.043806, 6), ]
# Sulfate
boxplot.stats(datos$Sulfate, coef = 3)
datos$Sulfate <- as.numeric(trimws(datos$Sulfate))
datos <- datos[datos$Sulfate != 129, ]
boxplot.stats(datos$Sulfate, coef = 2)
datos <- datos[round(datos$Sulfate, 4) != round(180.2067, 4), ]
datos <- datos[round(datos$Sulfate, 4) != round(481.0306, 4), ]
datos <- datos[round(datos$Sulfate, 4) != round(476.5397, 4), ]
datos <- datos[round(datos$Sulfate, 4) != round(475.7375, 4), ]
# Conductivity
boxplot.stats(datos$Conductivity, coef = 3)
boxplot.stats(datos$Conductivity, coef = 2)
datos <- datos[round(datos$Conductivity, 4) != round(753.3426, 4), ]
# Organic carbon
boxplot.stats(datos$Organic_carbon, coef = 3)
boxplot.stats(datos$Organic_carbon, coef = 2)
datos <- datos[round(datos$Organic_carbon, 4) != round(27.00671, 5), ]
datos <- datos[round(datos$Organic_carbon, 4) != round(2.20000, 5), ]
# Trihalomethanes
boxplot.stats(datos$Trihalomethanes, coef = 3)
boxplot.stats(datos$Trihalomethanes, coef = 2)
datos <- datos[round(datos$Trihalomethanes, 6) != round(124.000000, 6), ]
datos <- datos[round(datos$Trihalomethanes, 6) != round(8.577013, 6), ]
# Turbidity
boxplot.stats(datos$Turbidity, coef = 3)

# Boxplot de la variable dependiente "ph" después de eliminar outliers
boxplot(datos$ph, main="Boxplot de ph (sin outliers)", ylab="ph", range = 3)

# Boxplots de las variables independientes después de eliminar outliers
for (col in colnames(datos)) {
  if (col != "ph") {
    boxplot(datos[, col], main=paste("Boxplot de", col, "(sin outliers)"), ylab=col, range = 3)
  }
}
boxplot(datos$ph, main="Boxplot de ph", ylab="ph")

# Boxplots de las variables independientes
for (col in colnames(datos)) {
  if (col != "ph") {
    boxplot(datos[, col], main=paste("Boxplot de", col), ylab=col)
  }
}

dim(datos)
summary(datos)

# Calculamos correlacion
cor(x=datos, method="spearman")
# No es necesario eliminar nada dado que no hay una correlacion mayor que 0,7 ni menor que -0,7

# Mostrar correlaciones actualizadas
corrplot(corr = cor(x = datos, method = "spearman"), method = "number",
         tl.cex = 1,number.cex = 1, cl.pos = "n",
         main="Coeficiente de Spearman")

describe(datos)

# Ajustar modelo de regresión lineal
modelo <- lm(ph ~ ., data=datos)
summary(modelo) # Mostrar resumen del modelo ajustado

# Crear gráficos para cada variable sin outliers
par(mfrow = c(3, 3))  # 3 filas y 3 columnas
for (col in names(datos)) {
  hist(datos[[col]], main = col, xlab = col, col = "turquoise", border = "black")
}
# Restaurar la configuración original de par() para evitar efectos secundarios
par(mfrow = c(1, 1))


# Separamos en Train y Test
set.seed(1)
train = sample(c(TRUE,FALSE),size = nrow(datos), replace = TRUE, prob = c(0.7, 0.3))
datos.train = datos[train,]
datos.test = datos[!train,]

modelo <- lm(ph ~ .,data=datos.train)
summary(modelo) # Mostramos el modelo ajustado


## VALIDACIÓN CRUZADA k-folds
k <- 5 # Número de grupos igual a n
set.seed(5)
folds <- sample(x=1:k, size =nrow(datos.train), replace = TRUE)
cv.errors <- matrix(NA, k, 8, dimnames = list(NULL,paste(1:8)))
for (j in 1:k){
  regfit.best <- regsubsets(ph~., data=datos.train[folds !=j,])
  for (i in 1:8){
    pred <- predict.regsubsets(regfit.best, newdata=datos.train[folds==j,], id=i)
    cv.errors[j,i] <- mean((datos.train$ph[folds == j]-pred)^2)
  }
}
cv.errors

mean.cv.errors <- apply(cv.errors, 2, mean)
mean.cv.errors
coef(regfit.best, which.min(mean.cv.errors))
# Comprobación
model.cv <- lm(ph ~ Hardness + Solids, data=datos.train)
summary(model.cv)
plot(lm(ph ~ Hardness + Solids, data=datos.train))
plot(lm(ph ~ Hardness + Solids, data=datos.train), which=c(1,2))
residualPlot(model.cv)
influenceIndexPlot(model.cv)
durbinWatsonTest(model.cv)

# Por los valores obtenidos podemos concluir que no existe multicolinealidad entre las variables
(vif=vif(model.cv))
(tol=1/vif)

# Por ultimo, evaluamos los supuestos de normalidad, independencia y homocedasticidad.
summary(model.cv)
confint(model.cv) # Mostramos los intervalos de confianza de los coeficientes
# Obtén los residuos del modelo de regresión
residuos <- model.cv$residuals

# Visualización inicial de los residuos
plot(residuos)
hist(residuos)
boxplot(residuos)

# Quitar observaciones influyentes
#obtenemos los ´ındices y los valores con leverage alto
leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos2=datos.train[-outliers[6],]
rownames(datos2)=1:nrow(datos2) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos2)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos3=datos2[-outliers[5],]
rownames(datos3)=1:nrow(datos3) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos3)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos4=datos3[-outliers[2],]
rownames(datos4)=1:nrow(datos4) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos4)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos5=datos4[-outliers[2],]
rownames(datos5)=1:nrow(datos5) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos5)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos6=datos5[-outliers[5],]
rownames(datos6)=1:nrow(datos6) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos6)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos7=datos6[-outliers[1],]
rownames(datos7)=1:nrow(datos7) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos7)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos8=datos7[-outliers[1],]
rownames(datos8)=1:nrow(datos8) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos8)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos9=datos8[-outliers[3],]
rownames(datos9)=1:nrow(datos9) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos9)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos10=datos9[-outliers[2],]
rownames(datos10)=1:nrow(datos10) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos10)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

datos11=datos10[-outliers[1],]
rownames(datos11)=1:nrow(datos11) #renombramos etiquetas de filas
model.cv <- lm(ph ~ Hardness + Solids, data=datos11)
summary(modelo) #mostramos el modelo ajustado

leverage=hatvalues(model.cv) #calculamos el valor de leverage
plot(leverage,type="h")
(leverage.alto=c(which(leverage>2)))
leverage[leverage.alto]
rest=rstudent(model.cv) #calculamos los residuos estudentizados
(outliers=c(which(rest>3),which(rest<(-3))))
rest[outliers] #obtenemos el valor del residuo estudentizado

plot(model.cv)

residuos <- model.cv$residuals

#Estudiamos la normalidad
lillie.test(residuos)

#Estudiamos la homocedasticidad
bptest(model.cv)

#Estudiamos la independencia
dwtest(model.cv)

# Observamos que los residuos verifican los tres supuestos anteriores.

#Calculamos el ECM y su raíz
pred = predict(model.cv,newdata=datos.test)
ECM = mean((pred-datos.test$ph)^2)
ECM
RMSE=(sqrt(ECM))
RMSE

# CP de Mallows
ols_mallows_cp(model.cv, modelo)

# Criterio de informacion de Akaike

modelos <- list(model.cv)
mod.names <- c("model.cv")
aictab(cand.set = modelos, modnames = mod.names)

# BIC
BIC(model.cv)


# MÉTODO RIDGE

x<-model.matrix(ph~.,datos.train)[,-1]
y<-datos.train$ph
grid<-10^seq(10,-2,length=100)
ridge.mod<-glmnet(x,y,alpha=0,lambda=grid)


x.train<-model.matrix(ph~.,datos.train)[,-1]
y.train<-datos.train$ph
x.test<-model.matrix(ph~.,datos.test)[,-1]
y.test<-datos.test$ph


set.seed(1)
cv.out<-cv.glmnet(x.train,y.train,alpha=0)
plot(cv.out)
(bestlam<-cv.out$lambda.min)

ridge.pred<-predict(ridge.mod,s=bestlam,newx=x.test)
ECM = mean((ridge.pred-y.test)^2)
ECM
RMSE=(sqrt(ECM))
RMSE

out<-glmnet(x,y,alpha=0)
ridge.coef = predict(out,type="coefficients",s=bestlam)
ridge.coef


# Calcular el Cp de Mallows
n <- length(y.test)
d <- sum(ridge.coef != 0)  # Número de predictores en el modelo
RSS <- sum((y.test - ridge.pred)^2)
sigma_hat_sq <- RSS / (n - d)  # Estimación de la varianza del error

ridge_cpm <- (1/n) * (RSS + 2 * d * sigma_hat_sq)
ridge_cpm

# R2 ajustado
r2 = 1 - (RSS / sum((y.test - mean(y.test)) ^ 2))
r2_ajustado = 1 - (1 - r2) * ((n - 1) / (n - d - 1))
r2_ajustado

# Calcular el AIC
ridge_aic <- (1/n * sigma_hat_sq) * (RSS + 2 * d * sigma_hat_sq)
ridge_aic

# Calcular BIC
ridge_bic = (1/n) * (RSS + log(n) * d * sigma_hat_sq)
ridge_bic

# Gráfico de coeficientes Ridge
plot(ridge.mod, xvar="lambda", label=TRUE)


# MÉTODO LASSO

lasso.mod<-glmnet(x.train,y.train,alpha=1,lambda=grid)
plot(lasso.mod)

set.seed(1)
cv.out<-cv.glmnet(x.train,y.train,alpha=1)
plot(cv.out)
bestlam<-cv.out$lambda.min
bestlam
lasso.pred<-predict(lasso.mod,s=bestlam,newx=x.test)
mean((lasso.pred-y.test)^2)
sqrt(mean((lasso.pred-y.test)^2))

out<-glmnet(x,y,alpha=1,lambda=grid)
lasso.coef<-predict(out,type="coefficients",s=bestlam)
lasso.coef
lasso.coef[lasso.coef!=0]

# Calcular el Cp de Mallows
d <- sum(lasso.coef != 0)  # Número de predictores en el modelo
RSS <- sum((y.test - lasso.pred)^2)
sigma_hat_sq <- RSS / (n - d)  # Estimación de la varianza del error

lasso_cpm <- (1/n) * (RSS + 2 * d * sigma_hat_sq)
lasso_cpm

# R2 ajustado
r2 = 1 - (RSS / sum((y.test - mean(y.test)) ^ 2))
r2_ajustado = 1 - (1 - r2) * ((n - 1) / (n - d - 1))
r2_ajustado

# Calcular el AIC
lasso_aic <- (1/n * sigma_hat_sq) * (RSS + 2 * d * sigma_hat_sq)
lasso_aic

# Calcular BIC
lasso_bic = (1/n) * (RSS + log(n) * d * sigma_hat_sq)
lasso_bic

# Gráfico de coeficientes Lasso
plot(lasso.mod, xvar="lambda", label=TRUE)


# MÉTODO ELASTIC NET

# En caso de querer seleccionar el valor de α que minimice el ECM del modelo, lo podemos
# obtener comenzando con el siguiente bucle:

models <- list()
for (i in 0:20) {
  name <- paste0("alpha", i/20)
  models[[name]] <-
    cv.glmnet(x.train,y.train, type.measure="mse", alpha=i/20)
}

# Con este bucle, hemos ejecutado la funcion cv.glmnet() 21 veces, cada una de ellas con
# un valor de α diferente, tomando incrementos de tamaño 0.05. Queremos explorar estos
# modelos mas de cerca para ver cual produce el mejor ajuste del modelo,

results <- data.frame()
for (i in 0:20) {
  name <- paste0("alpha", i/20)
  ## Utilizamos cada modelo para predecir ’y’ dado el conjunto de datos de prueba
  predicted <- predict(models[[name]],
                       s=models[[name]]$lambda.min, newx=x.test)
  ## Calculamos el ECM
  mse <- mean((predicted-y.test)^2)
  ## Almacenamos los resultados
  temp <- data.frame(alpha=i/20, lambda=models[[name]]$lambda.min, mse=mse, name=name)
  results <- rbind(results, temp)
}
print(results)

plot(results$alpha, results$mse)
pos.min=which.min(results$mse)
(minimo=results[pos.min,])

# Como podemos ver, el valor de α que produce el mejor ajuste (minimiza el ECM) es 0.25
# y el modelo resultante contiene los siguientes predictores:
out<-glmnet(x,y,alpha=minimo$alpha,lambda=minimo$lambda)
elasnet.coef<-predict(out,type="coefficients",s=bestlam)
elasnet.coef
elasnet.coef[elasnet.coef!=0]

# Calcular el Cp de Mallows
d <- sum(elasnet.coef != 0)  # Número de predictores en el modelo
elasnet.pred <- predict(out, s = minimo$lambda, newx = x.test)
RSS <- sum((y.test - elasnet.pred)^2)
sigma_hat_sq <- RSS / (n - d)  # Estimación de la varianza del error

elasnet_cpm <- (1/n) * (RSS + 2 * d * sigma_hat_sq)
elasnet_cpm

# R2 ajustado
r2 = 1 - (RSS / sum((y.test - mean(y.test)) ^ 2))
r2_ajustado = 1 - (1 - r2) * ((n - 1) / (n - d - 1))
r2_ajustado

# Calcular el AIC
elasnet_aic <- (1/n * sigma_hat_sq) * (RSS + 2 * d * sigma_hat_sq)
elasnet_aic

# Calcular BIC
elasnet_bic = (1/n) * (RSS + log(n) * d * sigma_hat_sq)
elasnet_bic



# MÉTODOS DE REDUCCIÓN DE DIMENSIONES

# PCR

set.seed(1)
pcr.fit<-pcr(ph~.,data=datos.train,scale=TRUE,validation="CV")
validationplot(pcr.fit,val.type="MSEP")
MSEP(pcr.fit)

# Ahora encontramos que el error de validacion cruzada mas bajo ocurre cuando se usan M = 2 componentes. Calculamos el ECM en el conjunto de prueba de la siguiente manera.
pcr.pred<-predict(pcr.fit,x.test,ncomp=2)
mean((pcr.pred-y.test)^2)
sqrt(mean((pcr.pred-y.test)^2))

# Calcular el Cp de Mallows
n <- length(y.test)
d <- 2 # ncomp
RSS <- sum((y.test - pcr.pred)^2)
sigma_hat_sq <- RSS / (n - 2)  # Estimación de la varianza del error

pcr_cpm <- (1/n) * (RSS + 2 * d * sigma_hat_sq)
pcr_cpm

# R2 ajustado
r2 = 1 - (RSS / sum((y.test - mean(y.test)) ^ 2))
r2_ajustado = 1 - (1 - r2) * ((n - 1) / (n - d - 1))
r2_ajustado

# Calcular el AIC
pcr_aic <- (1/n * sigma_hat_sq) * (RSS + 2 * d * sigma_hat_sq)
pcr_aic

# Calcular BIC
pcr_bic = (1/n) * (RSS + log(n) * d * sigma_hat_sq)
pcr_bic


# PLS (el enfoque PLS intenta encontrar direcciones que ayuden a explicar tanto la respuesta como los predictores)

set.seed(1)
pls.fit<-plsr(ph~., data = datos.train, scale = TRUE, validation = "CV")
summary(pls.fit)
validationplot(pls.fit,val.type="MSEP")

# Realizamos ahora el PLS usando el conjunto de datos train, usando M = 1, el numero de
# componentes identificados por validacion cruzada.
pls.fit<-plsr(ph~.,data=datos.train,scale=TRUE,ncomp=1)
summary(pls.fit)

# Ahora evaluamos el correspondiente ECM del conjunto de prueba.
pls.pred<-predict(pls.fit,x.test,ncomp=1)
mean((pls.pred-y.test)^2)
sqrt(mean((pls.pred-y.test)^2))

# Calcular el Cp de Mallows
n <- length(y.test)
d <- 1 # ncomp
RSS <- sum((y.test - pls.pred)^2)
sigma_hat_sq <- RSS / (n - 2)  # Estimación de la varianza del error

pls_cpm <- (1/n) * (RSS + 2 * d * sigma_hat_sq)
pls_cpm

# R2 ajustado
r2 = 1 - (RSS / sum((y.test - mean(y.test)) ^ 2))
r2_ajustado = 1 - (1 - r2) * ((n - 1) / (n - d - 1))
r2_ajustado

# Calcular el AIC
pls_aic <- (1/n * sigma_hat_sq) * (RSS + 2 * d * sigma_hat_sq)
pls_aic

# Calcular BIC
pcr_bic = (1/n) * (RSS + log(n) * d * sigma_hat_sq)
pcr_bic


# REGRESIÓN LOGÍSTICA
names(datos_logistica) #obtenemos los nombres de las caracterısticas
dim(datos_logistica) #obtenemos la dimension de la matriz
summary(datos_logistica)

par(mfrow = c(3, 3))

# Boxplot de la variable dependiente "ph"
boxplot(datos_logistica$ph, main="Boxplot de ph", ylab="ph", range = 3)

# Boxplots de las variables independientes
for (col in colnames(datos_logistica)) {
  if (col != "ph") {
    boxplot(datos_logistica[, col], main=paste("Boxplot de", col), ylab=col, range = 3)
  }
}

boxplot(datos_logistica$ph, main="Boxplot de ph", ylab="ph")

# Boxplots de las variables independientes
for (col in colnames(datos_logistica)) {
  if (col != "ph") {
    boxplot(datos_logistica[, col], main=paste("Boxplot de", col), ylab=col)
  }
}

# Eliminar outliers influyentes y algunos no influyentes
# PH
boxplot.stats(datos_logistica$ph, coef = 3)
datos_logistica$ph <- as.numeric(trimws(datos_logistica$ph))
datos_logistica <- datos_logistica[datos_logistica$ph != 14, ]
boxplot.stats(datos_logistica$ph, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$ph, 7) != round(13.3498886, 7), ]
datos_logistica <- datos_logistica[round(datos_logistica$ph, 7) != round(0.2274991, 7), ]
datos_logistica <- datos_logistica[round(datos_logistica$ph, 7) != round(0.9899122, 7), ]
# Hardness
boxplot.stats(datos_logistica$Hardness, coef = 3)
boxplot.stats(datos_logistica$Hardness, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$Hardness, 5) != round(317.33812, 5), ]
datos_logistica <- datos_logistica[round(datos_logistica$Hardness, 5) != round(306.62748, 5), ]
datos_logistica <- datos_logistica[round(datos_logistica$Hardness, 5) != round(300.29248, 5), ]
datos_logistica <- datos_logistica[round(datos_logistica$Hardness, 5) != round(73.49223, 5), ]
datos_logistica <- datos_logistica[round(datos_logistica$Hardness, 5) != round(77.45959, 5), ]
datos_logistica <- datos_logistica[round(datos_logistica$Hardness, 5) != round(81.71090, 5), ]
# Solids
boxplot.stats(datos_logistica$Solids, coef = 3)
boxplot.stats(datos_logistica$Solids, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$Solids, 2) != round(56488.67, 2), ]
datos_logistica <- datos_logistica[round(datos_logistica$Solids, 2) != round(56351.40, 2), ]
# Chloramines
boxplot.stats(datos_logistica$Chloramines, coef = 3)
boxplot.stats(datos_logistica$Chloramines, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$Chloramines, 6) != round(1.390871, 6), ]
datos_logistica <- datos_logistica[round(datos_logistica$Chloramines, 6) != round(1.920271, 6), ]
datos_logistica <- datos_logistica[round(datos_logistica$Chloramines, 6) != round(13.127000, 6), ]
datos_logistica <- datos_logistica[round(datos_logistica$Chloramines, 6) != round(13.043806, 6), ]
# Sulfate
boxplot.stats(datos_logistica$Sulfate, coef = 3)
datos_logistica$Sulfate <- as.numeric(trimws(datos_logistica$Sulfate))
datos_logistica <- datos_logistica[datos_logistica$Sulfate != 129, ]
boxplot.stats(datos_logistica$Sulfate, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$Sulfate, 4) != round(180.2067, 4), ]
datos_logistica <- datos_logistica[round(datos_logistica$Sulfate, 4) != round(481.0306, 4), ]
datos_logistica <- datos_logistica[round(datos_logistica$Sulfate, 4) != round(476.5397, 4), ]
datos_logistica <- datos_logistica[round(datos_logistica$Sulfate, 4) != round(475.7375, 4), ]
# Conductivity
boxplot.stats(datos_logistica$Conductivity, coef = 3)
boxplot.stats(datos_logistica$Conductivity, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$Conductivity, 4) != round(753.3426, 4), ]
# Organic carbon
boxplot.stats(datos_logistica$Organic_carbon, coef = 3)
boxplot.stats(datos_logistica$Organic_carbon, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$Organic_carbon, 4) != round(27.00671, 5), ]
datos_logistica <- datos_logistica[round(datos_logistica$Organic_carbon, 4) != round(2.20000, 5), ]
# Trihalomethanes
boxplot.stats(datos_logistica$Trihalomethanes, coef = 3)
boxplot.stats(datos_logistica$Trihalomethanes, coef = 2)
datos_logistica <- datos_logistica[round(datos_logistica$Trihalomethanes, 6) != round(124.000000, 6), ]
datos_logistica <- datos_logistica[round(datos_logistica$Trihalomethanes, 6) != round(8.577013, 6), ]
# Turbidity
boxplot.stats(datos_logistica$Turbidity, coef = 3)

# Boxplot de la variable dependiente "ph" después de eliminar outliers
boxplot(datos_logistica$ph, main="Boxplot de ph (sin outliers)", ylab="ph", range = 3)

# Boxplots de las variables independientes después de eliminar outliers
for (col in colnames(datos_logistica)) {
  if (col != "ph") {
    boxplot(datos_logistica[, col], main=paste("Boxplot de", col, "(sin outliers)"), ylab=col, range = 3)
  }
}
boxplot(datos_logistica$ph, main="Boxplot de ph", ylab="ph")

# Boxplots de las variables independientes
for (col in colnames(datos_logistica)) {
  if (col != "ph") {
    boxplot(datos_logistica[, col], main=paste("Boxplot de", col), ylab=col)
  }
}

dim(datos_logistica)
par(mfrow = c(1, 1))

umbral_ph <- 7

# Crear la variable dicotómica (más de 7 de ph es 1 lo que significa que el ph es alcalino, y al contrario que es ácido)
datos_logistica$ph_categorico <- ifelse(datos_logistica$ph >= umbral_ph, 1, 0)


modelo_logistico <- glm(ph_categorico ~ Hardness + Solids + Chloramines + Sulfate + Conductivity + Organic_carbon + Trihalomethanes + Turbidity, 
                        data = datos_logistica, 
                        family = binomial)

# Mostrar resumen del modelo
summary(modelo_logistico)


# Asegúrate de que ph_categorico sea un factor con dos niveles
datos_logistica$ph_categorico <- as.factor(datos_logistica$ph_categorico)


# Separa los datos en conjuntos de entrenamiento y prueba
set.seed(1)
train = sample(c(TRUE,FALSE),size = nrow(datos_logistica), replace = TRUE, prob = c(0.71, 0.29))
datos_logistica.train <- datos_logistica[train, ]
datos_logistica.test <- datos_logistica[-train, ]

modelo_logistica <- glm(ph_categorico ~ Hardness + Solids + Chloramines + Sulfate + Conductivity + Organic_carbon + Trihalomethanes + Turbidity, data=datos_logistica.train, family=binomial)
summary(modelo_logistica) # Mostramos el modelo ajustado


# Ajuste del modelo de regresión logística con validación cruzada LOOCV
model <- train(ph_categorico ~ Hardness,
               data = datos_logistica.train,
               method = "glm",
               family = binomial,
               trControl = trainControl(method = "LOOCV"))

levels(datos_logistica$ph_categorico)

# Mostrar un resumen del modelo
model

# Realizar predicciones en los datos de prueba
glm.pred <- predict(model, datos_logistica.test)

# Calcular la matriz de confusión
confusionMatrix(glm.pred, datos_logistica.test$ph_categorico)
# Definir las etiquetas de clase
classes <- c("Ácido", "Alcalino")
# Calcular la matriz de confusión
conf_mat <- confusionMatrix(factor(glm.pred), factor(datos_logistica.test$ph_categorico), positive = "1", dnn = c("Actual", "Predicted"), mode = "everything")

# Cambiar las etiquetas de clase en la matriz de confusión
rownames(conf_mat$table) <- classes
colnames(conf_mat$table) <- classes

# Mostrar la matriz de confusión
conf_mat$table


#                Actual
#                0 (Ácido)   1 (Alcalino)

# Predicted  0       TN            FP
#            1       FN            TP

#TN (True Negative): Observaciones que son correctamente clasificadas como ácidas (clase 0).
#FP (False Positive): Observaciones que son incorrectamente clasificadas como alcalinas (clase 1), pero son ácidas (clase 0).
#FN (False Negative): Observaciones que son incorrectamente clasificadas como ácidas (clase 0), pero son alcalinas (clase 1).
#TP (True Positive): Observaciones que son correctamente clasificadas como alcalinas (clase 1).

VP=conf_mat$table[1,1]
VN=conf_mat$table[2,2]
FP=conf_mat$table[1,2]
FN=conf_mat$table[2,1]
(accuracy=(VP+VN)/(VP+FN+VN+FP)) # En conclusión, tengo un 56'41% de acierto.
(error=(FN+FP)/(VP+FN+VN+FP))
(sensibilidad=VP/(VP+FN))
(especificidad=VN/(VN+FP))
(vpp=VP/(VP+FP))
(vpn=VN/(VN+FN))
(F1=2*(vpp*sensibilidad)/(vpp+sensibilidad))


# Área bajo la curva (AUC) para la curva ROC
pred <- prediction(as.numeric(glm.pred), as.numeric(datos_logistica.test$ph_categorico))
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE, type = "l")
abline(a = 0, b = 1)

# Calcular el AUC
AUC <- performance(pred, measure = "auc")
AUCaltura <- AUC@y.values
cat("AUC:", AUCaltura[[1]])
